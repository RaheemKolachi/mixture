{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkSsDvt0QNiW",
        "outputId": "9641b567-c26d-4c33-f7bc-4fb805a9a8d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  colordataset.zip\n",
            "   creating: colordataset/hairs/\n",
            "   creating: colordataset/hairs/black hairs/\n",
            "  inflating: colordataset/hairs/black hairs/data10.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data102.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data103.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data106.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data107.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data11.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data110.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data111.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data113.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data114.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data115.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data117.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data12.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data122.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data123.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data124.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data126.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data127.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data13.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data131.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data133.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data134.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data138.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data139.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data141.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data146.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data149.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data15.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data150.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data152.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data154.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data155.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data156.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data159.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data16.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data19.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data2.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data24.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data25.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data26.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data29.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data3.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data31.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data32.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data33.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data34.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data36.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data38.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data39.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data4.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data40.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data41.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data42.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data47.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data5.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data51.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data52.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data53.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data55.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data56.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data59.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data6.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data61.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data62.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data64.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data65.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data66.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data69.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data70.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data73.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data75.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data77.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data78.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data79.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data80.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data82.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data83.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data85.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data86.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data92.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data95.jpg  \n",
            "  inflating: colordataset/hairs/black hairs/data98.jpg  \n",
            "   creating: colordataset/hairs/white hairs/\n",
            "  inflating: colordataset/hairs/white hairs/data100.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data112.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data116.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data120.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data121.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data128.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data129.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data14.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data148.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data17.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data20.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data22.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data23.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data28.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data37.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data44.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data45.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data46.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data48.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data54.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data58.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data67.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data7.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data76.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data87.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data88.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data9.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data90.jpg  \n",
            "  inflating: colordataset/hairs/white hairs/data96.jpg  \n",
            "   creating: colordataset/train/\n",
            "   creating: colordataset/train/black skin/\n",
            "  inflating: colordataset/train/black skin/data1 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data1.jpg  \n",
            "  inflating: colordataset/train/black skin/data106 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data106.jpg  \n",
            "  inflating: colordataset/train/black skin/data107 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data107.jpg  \n",
            "  inflating: colordataset/train/black skin/data11 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data11.jpg  \n",
            "  inflating: colordataset/train/black skin/data113 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data113.jpg  \n",
            "  inflating: colordataset/train/black skin/data117 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data117.jpg  \n",
            "  inflating: colordataset/train/black skin/data131 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data131.jpg  \n",
            "  inflating: colordataset/train/black skin/data132 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data132.jpg  \n",
            "  inflating: colordataset/train/black skin/data133 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data133.jpg  \n",
            "  inflating: colordataset/train/black skin/data137 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data137.jpg  \n",
            "  inflating: colordataset/train/black skin/data138 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data138.jpg  \n",
            "  inflating: colordataset/train/black skin/data141 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data141.jpg  \n",
            "  inflating: colordataset/train/black skin/data146 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data146.jpg  \n",
            "  inflating: colordataset/train/black skin/data152 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data152.jpg  \n",
            "  inflating: colordataset/train/black skin/data29 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data29.jpg  \n",
            "  inflating: colordataset/train/black skin/data3 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data3.jpg  \n",
            "  inflating: colordataset/train/black skin/data36 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data36.jpg  \n",
            "  inflating: colordataset/train/black skin/data39 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data39.jpg  \n",
            "  inflating: colordataset/train/black skin/data42 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data42.jpg  \n",
            "  inflating: colordataset/train/black skin/data48 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data48.jpg  \n",
            "  inflating: colordataset/train/black skin/data51 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data51.jpg  \n",
            "  inflating: colordataset/train/black skin/data61 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data61.jpg  \n",
            "  inflating: colordataset/train/black skin/data69 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data69.jpg  \n",
            "  inflating: colordataset/train/black skin/data77 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data77.jpg  \n",
            "  inflating: colordataset/train/black skin/data80 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data80.jpg  \n",
            "  inflating: colordataset/train/black skin/data83 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data83.jpg  \n",
            "  inflating: colordataset/train/black skin/data97 - Copy.jpg  \n",
            "  inflating: colordataset/train/black skin/data97.jpg  \n",
            "   creating: colordataset/train/white skin/\n",
            "  inflating: colordataset/train/white skin/data10.jpg  \n",
            "  inflating: colordataset/train/white skin/data100.jpg  \n",
            "  inflating: colordataset/train/white skin/data102.jpg  \n",
            "  inflating: colordataset/train/white skin/data103.jpg  \n",
            "  inflating: colordataset/train/white skin/data104.jpg  \n",
            "  inflating: colordataset/train/white skin/data105.jpg  \n",
            "  inflating: colordataset/train/white skin/data108.jpg  \n",
            "  inflating: colordataset/train/white skin/data109.jpg  \n",
            "  inflating: colordataset/train/white skin/data110.jpg  \n",
            "  inflating: colordataset/train/white skin/data111.jpg  \n",
            "  inflating: colordataset/train/white skin/data112.jpg  \n",
            "  inflating: colordataset/train/white skin/data114.jpg  \n",
            "  inflating: colordataset/train/white skin/data115.jpg  \n",
            "  inflating: colordataset/train/white skin/data116.jpg  \n",
            "  inflating: colordataset/train/white skin/data118.jpg  \n",
            "  inflating: colordataset/train/white skin/data12.jpg  \n",
            "  inflating: colordataset/train/white skin/data120.jpg  \n",
            "  inflating: colordataset/train/white skin/data121.jpg  \n",
            "  inflating: colordataset/train/white skin/data122.jpg  \n",
            "  inflating: colordataset/train/white skin/data123.jpg  \n",
            "  inflating: colordataset/train/white skin/data124.jpg  \n",
            "  inflating: colordataset/train/white skin/data126.jpg  \n",
            "  inflating: colordataset/train/white skin/data127.jpg  \n",
            "  inflating: colordataset/train/white skin/data128.jpg  \n",
            "  inflating: colordataset/train/white skin/data129.jpg  \n",
            "  inflating: colordataset/train/white skin/data13.jpg  \n",
            "  inflating: colordataset/train/white skin/data134.jpg  \n",
            "  inflating: colordataset/train/white skin/data14.jpg  \n",
            "  inflating: colordataset/train/white skin/data147.jpg  \n",
            "  inflating: colordataset/train/white skin/data148.jpg  \n",
            "  inflating: colordataset/train/white skin/data149.jpg  \n",
            "  inflating: colordataset/train/white skin/data15.jpg  \n",
            "  inflating: colordataset/train/white skin/data150.jpg  \n",
            "  inflating: colordataset/train/white skin/data154.jpg  \n",
            "  inflating: colordataset/train/white skin/data155.jpg  \n",
            "  inflating: colordataset/train/white skin/data156.jpg  \n",
            "  inflating: colordataset/train/white skin/data159.jpg  \n",
            "  inflating: colordataset/train/white skin/data16.jpg  \n",
            "  inflating: colordataset/train/white skin/data17.jpg  \n",
            "  inflating: colordataset/train/white skin/data19.jpg  \n",
            "  inflating: colordataset/train/white skin/data2.jpg  \n",
            "  inflating: colordataset/train/white skin/data20.jpg  \n",
            "  inflating: colordataset/train/white skin/data21.jpg  \n",
            "  inflating: colordataset/train/white skin/data22.jpg  \n",
            "  inflating: colordataset/train/white skin/data23.jpg  \n",
            "  inflating: colordataset/train/white skin/data25.jpg  \n",
            "  inflating: colordataset/train/white skin/data26.jpg  \n",
            "  inflating: colordataset/train/white skin/data28.jpg  \n",
            "  inflating: colordataset/train/white skin/data31.jpg  \n",
            "  inflating: colordataset/train/white skin/data32.jpg  \n",
            "  inflating: colordataset/train/white skin/data33.jpg  \n",
            "  inflating: colordataset/train/white skin/data34.jpg  \n",
            "  inflating: colordataset/train/white skin/data37.jpg  \n",
            "  inflating: colordataset/train/white skin/data38.jpg  \n",
            "  inflating: colordataset/train/white skin/data4.jpg  \n",
            "  inflating: colordataset/train/white skin/data40.jpg  \n",
            "  inflating: colordataset/train/white skin/data44.jpg  \n",
            "  inflating: colordataset/train/white skin/data45.jpg  \n",
            "  inflating: colordataset/train/white skin/data46.jpg  \n",
            "  inflating: colordataset/train/white skin/data47.jpg  \n",
            "  inflating: colordataset/train/white skin/data5.jpg  \n",
            "  inflating: colordataset/train/white skin/data52.jpg  \n",
            "  inflating: colordataset/train/white skin/data53.jpg  \n",
            "  inflating: colordataset/train/white skin/data54.jpg  \n",
            "  inflating: colordataset/train/white skin/data55.jpg  \n",
            "  inflating: colordataset/train/white skin/data56.jpg  \n",
            "  inflating: colordataset/train/white skin/data58.jpg  \n",
            "  inflating: colordataset/train/white skin/data59.jpg  \n",
            "  inflating: colordataset/train/white skin/data6.jpg  \n",
            "  inflating: colordataset/train/white skin/data62.jpg  \n",
            "  inflating: colordataset/train/white skin/data64.jpg  \n",
            "  inflating: colordataset/train/white skin/data65.jpg  \n",
            "  inflating: colordataset/train/white skin/data66.jpg  \n",
            "  inflating: colordataset/train/white skin/data67.jpg  \n",
            "  inflating: colordataset/train/white skin/data7.jpg  \n",
            "  inflating: colordataset/train/white skin/data70.jpg  \n",
            "  inflating: colordataset/train/white skin/data73.jpg  \n",
            "  inflating: colordataset/train/white skin/data75.jpg  \n",
            "  inflating: colordataset/train/white skin/data76.jpg  \n",
            "  inflating: colordataset/train/white skin/data78.jpg  \n",
            "  inflating: colordataset/train/white skin/data79.jpg  \n",
            "  inflating: colordataset/train/white skin/data8.jpg  \n",
            "  inflating: colordataset/train/white skin/data82.jpg  \n",
            "  inflating: colordataset/train/white skin/data85.jpg  \n",
            "  inflating: colordataset/train/white skin/data86.jpg  \n",
            "  inflating: colordataset/train/white skin/data87.jpg  \n",
            "  inflating: colordataset/train/white skin/data88.jpg  \n",
            "  inflating: colordataset/train/white skin/data9.jpg  \n",
            "  inflating: colordataset/train/white skin/data90.jpg  \n",
            "  inflating: colordataset/train/white skin/data92.jpg  \n",
            "  inflating: colordataset/train/white skin/data93.jpg  \n",
            "  inflating: colordataset/train/white skin/data95.jpg  \n",
            "  inflating: colordataset/train/white skin/data96.jpg  \n",
            "  inflating: colordataset/train/white skin/data98.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"colordataset\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Model definition\n",
        "def create_model():\n",
        "    input_hair = Input(shape=(64, 64, 3))\n",
        "    input_skin = Input(shape=(64, 64, 3))\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(input_hair)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    out_hair = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    y = Conv2D(32, (3, 3), activation='relu')(input_skin)\n",
        "    y = MaxPooling2D((2, 2))(y)\n",
        "    y = Conv2D(64, (3, 3), activation='relu')(y)\n",
        "    y = MaxPooling2D((2, 2))(y)\n",
        "    y = Flatten()(y)\n",
        "    out_skin = Dense(2, activation='softmax')(y)\n",
        "\n",
        "    model = Model(inputs=[input_hair, input_skin], outputs=[out_hair, out_skin])\n",
        "\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss=['sparse_categorical_crossentropy', 'sparse_categorical_crossentropy'], \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Data loading\n",
        "def load_data(hair_dir, skin_dir):\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "    train_hair_generator = datagen.flow_from_directory(\n",
        "        hair_dir,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "\n",
        "    validation_hair_generator = datagen.flow_from_directory(\n",
        "        hair_dir,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation')\n",
        "\n",
        "    train_skin_generator = datagen.flow_from_directory(\n",
        "        skin_dir,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "\n",
        "    validation_skin_generator = datagen.flow_from_directory(\n",
        "        skin_dir,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation')\n",
        "\n",
        "    return train_hair_generator, validation_hair_generator, train_skin_generator, validation_skin_generator\n",
        "\n",
        "# Model training\n",
        "# Model training\n",
        "def train_model(model, train_hair_generator, train_skin_generator, validation_hair_generator, validation_skin_generator):\n",
        "    def multi_generator(generator1, generator2):\n",
        "        while True:\n",
        "            x1, y1 = next(generator1)\n",
        "            x2, y2 = next(generator2)\n",
        "            yield [x1, x2], [y1, y2]\n",
        "\n",
        "    train_multi_generator = multi_generator(train_hair_generator, train_skin_generator)\n",
        "    validation_multi_generator = multi_generator(validation_hair_generator, validation_skin_generator)\n",
        "\n",
        "    model.fit(train_multi_generator,\n",
        "              steps_per_epoch=len(train_hair_generator),\n",
        "              validation_data=validation_multi_generator,\n",
        "              validation_steps=len(validation_hair_generator),\n",
        "              epochs=10,verbose=2)\n",
        "\n",
        "# Paths to image directories\n",
        "hair_dir = '/content/colordataset/hairs'\n",
        "skin_dir = '/content/colordataset/train'\n",
        "\n",
        "# Load data\n",
        "train_hair_generator, validation_hair_generator, train_skin_generator, validation_skin_generator = load_data(hair_dir, skin_dir)\n",
        "\n",
        "# Create and train model\n",
        "model = create_model()\n",
        "train_model(model, train_hair_generator, train_skin_generator, validation_hair_generator, validation_skin_generator)\n"
      ],
      "metadata": {
        "id": "wS7ztBOaRWOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848eae29-c568-4790-9c02-644f369d130c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 90 images belonging to 2 classes.\n",
            "Found 21 images belonging to 2 classes.\n",
            "Found 120 images belonging to 2 classes.\n",
            "Found 28 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "3/3 - 8s - loss: 1.3586 - dense_2_loss: 0.6921 - dense_3_loss: 0.6665 - dense_2_accuracy: 0.7333 - dense_3_accuracy: 0.6250 - val_loss: 1.1859 - val_dense_2_loss: 0.5978 - val_dense_3_loss: 0.5880 - val_dense_2_accuracy: 0.7619 - val_dense_3_accuracy: 0.6429 - 8s/epoch - 3s/step\n",
            "Epoch 2/10\n",
            "3/3 - 5s - loss: 1.1763 - dense_2_loss: 0.6038 - dense_3_loss: 0.5726 - dense_2_accuracy: 0.7333 - dense_3_accuracy: 0.6591 - val_loss: 1.1751 - val_dense_2_loss: 0.6095 - val_dense_3_loss: 0.5656 - val_dense_2_accuracy: 0.7143 - val_dense_3_accuracy: 0.6429 - 5s/epoch - 2s/step\n",
            "Epoch 3/10\n",
            "3/3 - 4s - loss: 1.1654 - dense_2_loss: 0.5862 - dense_3_loss: 0.5792 - dense_2_accuracy: 0.6889 - dense_3_accuracy: 0.6250 - val_loss: 1.0263 - val_dense_2_loss: 0.4870 - val_dense_3_loss: 0.5392 - val_dense_2_accuracy: 0.7619 - val_dense_3_accuracy: 0.6429 - 4s/epoch - 1s/step\n",
            "Epoch 4/10\n",
            "3/3 - 6s - loss: 1.0205 - dense_2_loss: 0.5293 - dense_3_loss: 0.4912 - dense_2_accuracy: 0.7444 - dense_3_accuracy: 0.7727 - val_loss: 0.9871 - val_dense_2_loss: 0.4718 - val_dense_3_loss: 0.5153 - val_dense_2_accuracy: 0.7619 - val_dense_3_accuracy: 0.7143 - 6s/epoch - 2s/step\n",
            "Epoch 5/10\n",
            "3/3 - 5s - loss: 0.9682 - dense_2_loss: 0.4711 - dense_3_loss: 0.4972 - dense_2_accuracy: 0.7556 - dense_3_accuracy: 0.7188 - val_loss: 0.9194 - val_dense_2_loss: 0.4279 - val_dense_3_loss: 0.4915 - val_dense_2_accuracy: 0.7619 - val_dense_3_accuracy: 0.7143 - 5s/epoch - 2s/step\n",
            "Epoch 6/10\n",
            "3/3 - 6s - loss: 0.8358 - dense_2_loss: 0.4664 - dense_3_loss: 0.3694 - dense_2_accuracy: 0.7556 - dense_3_accuracy: 0.8636 - val_loss: 0.8773 - val_dense_2_loss: 0.4209 - val_dense_3_loss: 0.4564 - val_dense_2_accuracy: 0.7619 - val_dense_3_accuracy: 0.7143 - 6s/epoch - 2s/step\n",
            "Epoch 7/10\n",
            "3/3 - 5s - loss: 0.8247 - dense_2_loss: 0.3878 - dense_3_loss: 0.4369 - dense_2_accuracy: 0.8333 - dense_3_accuracy: 0.8068 - val_loss: 0.9015 - val_dense_2_loss: 0.4855 - val_dense_3_loss: 0.4160 - val_dense_2_accuracy: 0.8095 - val_dense_3_accuracy: 0.7857 - 5s/epoch - 2s/step\n",
            "Epoch 8/10\n",
            "3/3 - 4s - loss: 0.7210 - dense_2_loss: 0.3585 - dense_3_loss: 0.3625 - dense_2_accuracy: 0.8667 - dense_3_accuracy: 0.8409 - val_loss: 0.7546 - val_dense_2_loss: 0.3652 - val_dense_3_loss: 0.3894 - val_dense_2_accuracy: 0.7619 - val_dense_3_accuracy: 0.7143 - 4s/epoch - 1s/step\n",
            "Epoch 9/10\n",
            "3/3 - 6s - loss: 0.6929 - dense_2_loss: 0.3684 - dense_3_loss: 0.3245 - dense_2_accuracy: 0.7889 - dense_3_accuracy: 0.8854 - val_loss: 0.7629 - val_dense_2_loss: 0.3493 - val_dense_3_loss: 0.4137 - val_dense_2_accuracy: 0.7619 - val_dense_3_accuracy: 0.7857 - 6s/epoch - 2s/step\n",
            "Epoch 10/10\n",
            "3/3 - 5s - loss: 0.6065 - dense_2_loss: 0.3221 - dense_3_loss: 0.2844 - dense_2_accuracy: 0.8556 - dense_3_accuracy: 0.8977 - val_loss: 0.8668 - val_dense_2_loss: 0.5345 - val_dense_3_loss: 0.3322 - val_dense_2_accuracy: 0.7619 - val_dense_3_accuracy: 0.8214 - 5s/epoch - 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the images\n",
        "def preprocess_image(image_path):\n",
        "    image = load_img(image_path, target_size=(64, 64))  # load and resize the image\n",
        "    image = img_to_array(image)  # convert the image to a numpy array\n",
        "    image = image / 255.0  # rescale the image\n",
        "    image = np.expand_dims(image, axis=0)  # add an extra dimension for the batch size\n",
        "    return image\n",
        "\n",
        "hair_image_path = '/content/colordataset/hairs/black hairs/data10.jpg'\n",
        "skin_image_path = '/content/colordataset/train/black skin/data1.jpg'\n",
        "\n",
        "hair_image = preprocess_image(hair_image_path)\n",
        "skin_image = preprocess_image(skin_image_path)\n",
        "\n",
        "# Predict with the model\n",
        "hair_prediction, skin_prediction = model.predict([hair_image, skin_image])\n",
        "\n",
        "# Get the class names\n",
        "hair_class_names = ['black hairs', 'white hairs']\n",
        "skin_class_names = ['black skin', 'white skin']\n",
        "\n",
        "# Get the predicted classes\n",
        "hair_predicted_class = hair_class_names[np.argmax(hair_prediction)]\n",
        "skin_predicted_class = skin_class_names[np.argmax(skin_prediction)]\n",
        "\n",
        "print(\"Hair prediction: \", hair_predicted_class)\n",
        "print(\"Skin prediction: \", skin_predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PCLbtboYYOj",
        "outputId": "d3111330-7138-47ac-cca1-971108de8948"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "Hair prediction:  black hairs\n",
            "Skin prediction:  black skin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflowjs as tfjs\n",
        "\n",
        "def save_model_tfjs(model, path):\n",
        "    tfjs.converters.save_keras_model(model, path)\n",
        "\n",
        "# Save the model\n",
        "save_model_tfjs(model, 'js_based_model')\n"
      ],
      "metadata": {
        "id": "CcUPyQDqX0DW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "tfjs.converters.save_keras_model(model, 'js_based_model')\n"
      ],
      "metadata": {
        "id": "bGbpF68FYPLd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YToco2wQZzyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}